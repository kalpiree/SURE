

# DUAR Framework: Dynamically Adaptive Uncertainty-aware Recommendations

This repository implements a pipeline to generate prediction sets with guaranteed performance with the DUAR framework.

---

## ğŸ” Pipeline Overview

### 1. **Data Preprocessing**
Generates phase-wise training and evaluation data.

- **Input:** raw userâ€“item interaction logs  
- **Output:**  
  ```
  processed_datasets/{dataset}/{subdataset}/phased_data/model_{id}/
      â”œâ”€â”€ train_phase{i}.txt
      â””â”€â”€ eval_phase{i}.csv
  ```

Each `train_phase{i}.txt` is a chronological split, and `eval_phase{i}.csv` includes per-user candidate sets and the true item.

---

### 2. **Model Training & Inference**
Train any sequential recommender (e.g., SASRec, FMLP-Rec) on each phase.

- **Input:** preprocessed data  
- **Output:** CSV files with model predictions:
  ```
  datasets_/{dataset}/{subdataset}/model_{id}/phase{i}_eval_output.csv
  ```

Each CSV must contain:
- `user_idx`
- `step`
- `true_item`
- `candidate_items` (as list)
- `scores` (matching candidate_items)
- `loss` (optional: for calibration)

---

### 3. **DUAR Calibration & Aggregation**
Use DUAR to calibrate models and adaptively ensemble them over time.

#### ğŸ§¹ Normalize Scores
```bash
python data/loader.py --dataset sasrec --subdataset goodreads --output_root datasets_
```

#### ğŸš€ Run DUAR
```bash
bash duar.sh
```

Or manually:
```bash
python main_.py \
  --dataset sasrec \
  --subdataset goodreads \
  --alphas 0.1 \
  --etas 0.5 \
  --gamma 2.0 \
  --base_utilities recall=0.67 \
  --output_dir outputs \
  --freeze_inference \
  --max_pred_set_size 50
```

- **Output:** Ensemble prediction stats and diagnostics:
  ```
  outputs/{dataset}/{subdataset}/alpha_{xxx}/detailed_snapshots.csv
  ```

---

## ğŸ§  DUAR Components

- `main_.py`: Entry point for DUAR. Runs lambda calibration + adaptive ensemble.
- `run_daur_.py`: Implements the time-evolving risk-driven aggregation loop.
- `calibration/`: Core calibration logic:
  - `adaptive_loop.py`: Adaptive Î» update based on segment-level risk
  - `aggregator_.py`: Model weighting and prediction set union
  - `lambda_search_.py`: Risk-controlled lambda search
  - `risk_estimator.py`: Empirical loss computation
  - `segment_shift.py`: Segment selection via concept/covariate shift
- `data/loader.py`: Normalizes model outputs into DUAR-ready format

---

## ğŸ“‚ Folder Structure

```
.
â”œâ”€â”€ data/
â”‚   â””â”€â”€ loader.py
â”œâ”€â”€ calibration/
â”‚   â”œâ”€â”€ adaptive_loop.py
â”‚   â”œâ”€â”€ aggregator_.py
â”‚   â”œâ”€â”€ lambda_search_.py
â”‚   â”œâ”€â”€ risk_estimator.py
â”‚   â”œâ”€â”€ segment_shift.py
â”‚   â””â”€â”€ set_constructor_.py
â”œâ”€â”€ main_.py
â”œâ”€â”€ run_daur_.py
â”œâ”€â”€ duar.sh
â”œâ”€â”€ datasets_/           # Normalized model predictions
â””â”€â”€ outputs/             # DUAR outputs
```

---

